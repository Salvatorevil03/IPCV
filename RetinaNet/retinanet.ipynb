{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13763433,"sourceType":"datasetVersion","datasetId":8758877},{"sourceId":13763536,"sourceType":"datasetVersion","datasetId":8758945}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Subset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:54:56.932962Z","iopub.execute_input":"2025-11-26T13:54:56.933514Z","iopub.status.idle":"2025-11-26T13:54:56.937777Z","shell.execute_reply.started":"2025-11-26T13:54:56.933484Z","shell.execute_reply":"2025-11-26T13:54:56.937174Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torchvision.datasets import CocoDetection\nfrom torchvision.transforms import functional as F\n\nclass COCODetectionRetinaNet(CocoDetection):\n    def __init__(self, img_folder, ann_file, transforms=None, max_images=None):\n        super().__init__(img_folder, ann_file)\n        self._transforms = transforms\n\n        # ðŸ”¥ FILTRA solo le immagini che esistono veramente su disco\n        valid_ids = []\n        for img_id in self.ids:\n            info = self.coco.loadImgs(img_id)[0]\n            fname = os.path.basename(info[\"file_name\"])\n            full_path = os.path.join(self.root, fname)\n            if os.path.exists(full_path):\n                valid_ids.append(img_id)\n\n        # Se vuoi ancora ridurre il dataset, puoi limitare il numero\n        if max_images is not None:\n            valid_ids = valid_ids[:max_images]\n\n        self.ids = valid_ids\n        print(f\"Using {len(self.ids)} valid images out of original {len(self.coco.getImgIds())}\")\n\n    def _load_image(self, id):\n        img_info = self.coco.loadImgs(id)[0]\n        path = img_info[\"file_name\"]\n        path = os.path.basename(path)  # ignoriamo eventuali sottocartelle strane\n        return Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n\n    def __getitem__(self, idx):\n        img, targets = super().__getitem__(idx)\n\n        boxes = []\n        labels = []\n        areas = []\n        iscrowd = []\n\n        for obj in targets:\n            if obj.get(\"iscrowd\", 0) == 1:\n                continue\n            x, y, w, h = obj[\"bbox\"]\n            x1 = x\n            y1 = y\n            x2 = x + w\n            y2 = y + h\n            boxes.append([x1, y1, x2, y2])\n            labels.append(obj[\"category_id\"])\n            areas.append(obj[\"area\"])\n            iscrowd.append(obj.get(\"iscrowd\", 0))\n\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        areas = torch.as_tensor(areas, dtype=torch.float32)\n        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n\n        target = {\n            \"boxes\": boxes,\n            \"labels\": labels,\n            \"area\": areas,\n            \"iscrowd\": iscrowd,\n            \"image_id\": torch.tensor([self.ids[idx]])\n        }\n\n        if self._transforms is not None:\n            img, target = self._transforms(img, target)\n\n        return img, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T12:30:36.945450Z","iopub.execute_input":"2025-11-26T12:30:36.946066Z","iopub.status.idle":"2025-11-26T12:30:45.778388Z","shell.execute_reply.started":"2025-11-26T12:30:36.946043Z","shell.execute_reply":"2025-11-26T12:30:45.777586Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# anchors.py\nimport math\nimport torch\n\nclass AnchorGenerator:\n    \"\"\"\n    Generate anchors for each FPN level.\n    sizes: list of base sizes per level, e.g. [32, 64, 128, 256, 512]\n    aspect_ratios: list, es. [0.5, 1.0, 2.0]\n    scales: list of scale factors per level, es. [1.0, 2 ** (1/3), 2 ** (2/3)]\n    \"\"\"\n    def __init__(self, sizes, aspect_ratios, scales):\n        self.sizes = sizes\n        self.aspect_ratios = aspect_ratios\n        self.scales = scales\n\n    def grid_anchors(self, grid_size, stride, base_size):\n        # grid_size: (h, w), stride: float\n        device = grid_size.device if isinstance(grid_size, torch.Tensor) else torch.device(\"cpu\")\n        h, w = int(grid_size[0]), int(grid_size[1])\n        shifts_x = torch.arange(0, w * stride, step=stride, device=device)\n        shifts_y = torch.arange(0, h * stride, step=stride, device=device)\n        shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x, indexing=\"ij\")\n        shift_x = shift_x.reshape(-1)\n        shift_y = shift_y.reshape(-1)\n\n        anchors = []\n        for scale in self.scales:\n            for ar in self.aspect_ratios:\n                area = (base_size * scale) ** 2.0\n                w_anchor = math.sqrt(area / ar)\n                h_anchor = ar * w_anchor\n                x1 = shift_x - 0.5 * w_anchor\n                y1 = shift_y - 0.5 * h_anchor\n                x2 = shift_x + 0.5 * w_anchor\n                y2 = shift_y + 0.5 * h_anchor\n                anchors_per = torch.stack([x1, y1, x2, y2], dim=1)\n                anchors.append(anchors_per)\n\n        anchors = torch.cat(anchors, dim=0)\n        return anchors\n\n    def __call__(self, feature_maps, strides):\n        \"\"\"\n        feature_maps: list of feature maps (tensor BxCxHxW)\n        strides: list of strides for each level (e.g. [8, 16, 32, 64, 128])\n        \"\"\"\n        all_anchors = []\n        for level, (fm, stride, size) in enumerate(zip(feature_maps, strides, self.sizes)):\n            _, _, h, w = fm.shape\n            anchors = self.grid_anchors((h, w), stride, size)\n            all_anchors.append(anchors)\n        return all_anchors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T12:30:51.036604Z","iopub.execute_input":"2025-11-26T12:30:51.037454Z","iopub.status.idle":"2025-11-26T12:30:51.045418Z","shell.execute_reply.started":"2025-11-26T12:30:51.037428Z","shell.execute_reply":"2025-11-26T12:30:51.044682Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# losses.py\nimport torch\nimport torch.nn.functional as F\n\ndef sigmoid_focal_loss(inputs, targets, alpha=0.25, gamma=2.0, reduction=\"sum\"):\n    \"\"\"\n    inputs: logits (N, num_classes)\n    targets: one-hot or {0,1} (N, num_classes)\n    \"\"\"\n    prob = torch.sigmoid(inputs)\n    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n    p_t = prob * targets + (1 - prob) * (1 - targets)\n    loss = ce_loss * ((1 - p_t) ** gamma)\n\n    if alpha >= 0:\n        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n        loss = alpha_t * loss\n\n    if reduction == \"mean\":\n        return loss.mean()\n    elif reduction == \"sum\":\n        return loss.sum()\n    return loss\n\n\ndef smooth_l1_loss(input, target, beta=1.0 / 9, reduction=\"sum\"):\n    \"\"\"\n    Smooth L1 as in Fast R-CNN.\n    \"\"\"\n    n = torch.abs(input - target)\n    cond = n < beta\n    loss = torch.where(cond, 0.5 * n ** 2 / beta, n - 0.5 * beta)\n    if reduction == \"mean\":\n        return loss.mean()\n    elif reduction == \"sum\":\n        return loss.sum()\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T12:54:32.789192Z","iopub.execute_input":"2025-11-26T12:54:32.789955Z","iopub.status.idle":"2025-11-26T12:54:32.831509Z","shell.execute_reply.started":"2025-11-26T12:54:32.789930Z","shell.execute_reply":"2025-11-26T12:54:32.830719Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.models import resnet50, ResNet50_Weights\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.models import resnet50, ResNet50_Weights\n\n\n# ---------- LOSSES ----------\n\ndef sigmoid_focal_loss(inputs, targets, alpha=0.25, gamma=2.0, reduction=\"sum\"):\n    \"\"\"\n    inputs: logits (N, num_classes)\n    targets: one-hot o {0,1} (N, num_classes)\n    \"\"\"\n    prob = torch.sigmoid(inputs)\n    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n    p_t = prob * targets + (1 - prob) * (1 - targets)\n    loss = ce_loss * ((1 - p_t) ** gamma)\n\n    if alpha >= 0:\n        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n        loss = alpha_t * loss\n\n    if reduction == \"mean\":\n        return loss.mean()\n    elif reduction == \"sum\":\n        return loss.sum()\n    return loss\n\n\ndef smooth_l1_loss(input, target, beta=1.0 / 9, reduction=\"sum\"):\n    \"\"\"\n    Smooth L1 come in Fast R-CNN.\n    \"\"\"\n    n = torch.abs(input - target)\n    cond = n < beta\n    loss = torch.where(cond, 0.5 * n ** 2 / beta, n - 0.5 * beta)\n    if reduction == \"mean\":\n        return loss.mean()\n    elif reduction == \"sum\":\n        return loss.sum()\n    return loss\n\n\n# ---------- Head (classification + regression) ----------\n\nclass RetinaNetHead(nn.Module):\n    def __init__(self, in_channels, num_anchors, num_classes):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n            nn.ReLU(),\n        )\n        self.cls_logits = nn.Conv2d(in_channels, num_anchors * num_classes, 3, padding=1)\n        self.bbox_pred = nn.Conv2d(in_channels, num_anchors * 4, 3, padding=1)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.normal_(m.weight, std=0.01)\n                nn.init.constant_(m.bias, 0)\n\n        # init del bias per cls (p ~ 0.01)\n        pi = 0.01\n        nn.init.constant_(self.cls_logits.bias, -torch.log(torch.tensor((1 - pi) / pi)))\n\n        self.num_classes = num_classes\n        self.num_anchors = num_anchors\n\n    def forward(self, xs):\n        logits = []\n        bbox_reg = []\n        for x in xs:\n            y = self.conv(x)\n            logits.append(self.cls_logits(y))\n            bbox_reg.append(self.bbox_pred(y))\n        return logits, bbox_reg\n\n\n# ---------- FPN ----------\n\nclass FPN(nn.Module):\n    def __init__(self, c3_channels, c4_channels, c5_channels, out_channels=256):\n        super().__init__()\n        self.lateral3 = nn.Conv2d(c3_channels, out_channels, 1)\n        self.lateral4 = nn.Conv2d(c4_channels, out_channels, 1)\n        self.lateral5 = nn.Conv2d(c5_channels, out_channels, 1)\n\n        self.out3 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n        self.out4 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n        self.out5 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n\n        self.p6 = nn.Conv2d(c5_channels, out_channels, 3, stride=2, padding=1)\n        self.p7 = nn.Conv2d(out_channels, out_channels, 3, stride=2, padding=1)\n\n    def forward(self, c3, c4, c5):\n        # top-down pathway\n        p5 = self.lateral5(c5)\n\n        # ðŸ‘‡ upsample esplicitando la size del livello corrispondente\n        p4 = self.lateral4(c4) + F.interpolate(p5, size=c4.shape[-2:], mode=\"nearest\")\n        p3 = self.lateral3(c3) + F.interpolate(p4, size=c3.shape[-2:], mode=\"nearest\")\n\n        p3 = self.out3(p3)\n        p4 = self.out4(p4)\n        p5 = self.out5(p5)\n\n        p6 = self.p6(c5)\n        p7 = self.p7(F.relu(p6))\n\n        return [p3, p4, p5, p6, p7]\n\n\n# ---------- Anchor generator ----------\n\nclass AnchorGenerator:\n    def __init__(self, sizes, aspect_ratios, scales):\n        self.sizes = sizes\n        self.aspect_ratios = aspect_ratios\n        self.scales = scales\n\n    def grid_anchors(self, grid_size, stride, base_size, device):\n        h, w = int(grid_size[0]), int(grid_size[1])\n        shifts_x = torch.arange(0, w * stride, step=stride, device=device)\n        shifts_y = torch.arange(0, h * stride, step=stride, device=device)\n        shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x, indexing=\"ij\")\n        shift_x = shift_x.reshape(-1)\n        shift_y = shift_y.reshape(-1)\n\n        anchors = []\n        for scale in self.scales:\n            for ar in self.aspect_ratios:\n                area = (base_size * scale) ** 2.0\n                w_anchor = torch.sqrt(torch.tensor(area / ar, device=device))\n                h_anchor = ar * w_anchor\n                x1 = shift_x - 0.5 * w_anchor\n                y1 = shift_y - 0.5 * h_anchor\n                x2 = shift_x + 0.5 * w_anchor\n                y2 = shift_y + 0.5 * h_anchor\n                anchors_per = torch.stack([x1, y1, x2, y2], dim=1)\n                anchors.append(anchors_per)\n\n        anchors = torch.cat(anchors, dim=0)\n        return anchors\n\n    def __call__(self, feature_maps, strides, device):\n        all_anchors = []\n        for fm, stride, size in zip(feature_maps, strides, self.sizes):\n            _, _, h, w = fm.shape\n            anchors = self.grid_anchors((h, w), stride, size, device)\n            all_anchors.append(anchors)\n        return all_anchors\n\n\n# ---------- Utility IoU / encoding ----------\n\ndef box_iou(boxes1, boxes2):\n    area1 = (boxes1[:, 2] - boxes1[:, 0]).clamp(min=0) * (boxes1[:, 3] - boxes1[:, 1]).clamp(min=0)\n    area2 = (boxes2[:, 2] - boxes2[:, 0]).clamp(min=0) * (boxes2[:, 3] - boxes2[:, 1]).clamp(min=0)\n\n    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # (N,M,2)\n    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])\n\n    wh = (rb - lt).clamp(min=0)\n    inter = wh[:, :, 0] * wh[:, :, 1]\n    union = area1[:, None] + area2 - inter\n    iou = inter / union.clamp(min=1e-6)\n    return iou\n\n\ndef encode_boxes(anchors, gt_boxes):\n    aw = anchors[:, 2] - anchors[:, 0]\n    ah = anchors[:, 3] - anchors[:, 1]\n    ax = anchors[:, 0] + 0.5 * aw\n    ay = anchors[:, 1] + 0.5 * ah\n\n    gw = gt_boxes[:, 2] - gt_boxes[:, 0]\n    gh = gt_boxes[:, 3] - gt_boxes[:, 1]\n    gx = gt_boxes[:, 0] + 0.5 * gw\n    gy = gt_boxes[:, 1] + 0.5 * gh\n\n    tx = (gx - ax) / aw\n    ty = (gy - ay) / ah\n    tw = torch.log(gw / aw)\n    th = torch.log(gh / ah)\n\n    return torch.stack([tx, ty, tw, th], dim=1)\n\n\n# ---------- RetinaNet completo ----------\n\nclass RetinaNet(nn.Module):\n    def __init__(self, num_classes, backbone_pretrained=True):\n        super().__init__()\n\n        # Backbone ResNet-50\n        weights = ResNet50_Weights.DEFAULT if backbone_pretrained else None\n        backbone = resnet50(weights=weights)\n        self.backbone = backbone\n\n        # canali C3, C4, C5\n        c3_channels = backbone.layer2[-1].conv3.out_channels\n        c4_channels = backbone.layer3[-1].conv3.out_channels\n        c5_channels = backbone.layer4[-1].conv3.out_channels\n\n        self.fpn = FPN(c3_channels, c4_channels, c5_channels, out_channels=256)\n\n        # Anchors\n        self.anchor_generator = AnchorGenerator(\n            sizes=[32, 64, 128, 256, 512],\n            aspect_ratios=[0.5, 1.0, 2.0],\n            scales=[1.0, 2 ** (1/3), 2 ** (2/3)]\n        )\n        num_anchors = len(self.anchor_generator.aspect_ratios) * len(self.anchor_generator.scales)\n        self.head = RetinaNetHead(256, num_anchors, num_classes)\n\n        self.strides = [8, 16, 32, 64, 128]\n\n    def extract_backbone_features(self, x):\n        # forward ResNet standard\n        x = self.backbone.conv1(x)\n        x = self.backbone.bn1(x)\n        x = self.backbone.relu(x)\n        x = self.backbone.maxpool(x)\n\n        c2 = self.backbone.layer1(x)  # /4\n        c3 = self.backbone.layer2(c2) # /8\n        c4 = self.backbone.layer3(c3) # /16\n        c5 = self.backbone.layer4(c4) # /32\n\n        return c3, c4, c5\n\n    def forward(self, images, targets=None):\n        # images: list di tensor [3,H,W] giÃ  pad-dati nel collate_fn\n        device = images[0].device\n        imgs = torch.stack(images, dim=0)   # (B,3,H,W)\n\n        c3, c4, c5 = self.extract_backbone_features(imgs)\n        features = self.fpn(c3, c4, c5)\n        cls_logits, bbox_reg = self.head(features)\n\n        # reshape\n        batch_size = imgs.size(0)\n        all_anchors = self.anchor_generator(features, self.strides, device)\n        anchors = torch.cat(all_anchors, dim=0)  # (A_total, 4)\n\n        cls_list = []\n        box_list = []\n        for l, b in zip(cls_logits, bbox_reg):\n            N, AxC, H, W = l.shape\n            Ax4 = b.shape[1]\n            A = Ax4 // 4\n            C = AxC // A\n\n            l = l.permute(0, 2, 3, 1).reshape(N, -1, C)\n            b = b.permute(0, 2, 3, 1).reshape(N, -1, 4)\n            cls_list.append(l)\n            box_list.append(b)\n\n        cls_out = torch.cat(cls_list, dim=1)   # (B, A_total, C)\n        box_out = torch.cat(box_list, dim=1)   # (B, A_total, 4)\n\n        if self.training:\n            assert targets is not None\n            loss_cls, loss_reg = self.compute_loss(cls_out, box_out, anchors, targets)\n            return {\"loss_cls\": loss_cls, \"loss_reg\": loss_reg}\n\n        # inference: per ora ritorniamo i raw output\n        return cls_out, box_out, anchors\n\n    def compute_loss(self, cls_out, box_out, anchors, targets):\n        device = cls_out.device\n        batch_size, num_anchors, num_classes = cls_out.shape\n\n        cls_targets = torch.zeros((batch_size, num_anchors, num_classes), device=device)\n        box_targets = torch.zeros((batch_size, num_anchors, 4), device=device)\n        box_mask = torch.zeros((batch_size, num_anchors), device=device)\n\n        for b_idx in range(batch_size):\n            gt_boxes = targets[b_idx][\"boxes\"].to(device)\n            gt_labels = targets[b_idx][\"labels\"].to(device)\n\n            if gt_boxes.numel() == 0:\n                continue\n\n            ious = box_iou(anchors.to(device), gt_boxes)  # (A,G)\n            max_iou, max_ids = ious.max(dim=1)\n\n            pos_mask = max_iou >= 0.5\n            neg_mask = max_iou < 0.4\n            ignore_mask = (~pos_mask) & (~neg_mask)\n\n            # cls targets\n            cls_targets[b_idx][neg_mask, :] = 0\n            cls_targets[b_idx][ignore_mask, :] = -1\n            cls_targets[b_idx][pos_mask, :] = 0\n\n            pos_gt = gt_labels[max_ids[pos_mask]]\n            cls_targets[b_idx][pos_mask, pos_gt] = 1\n\n            # box targets\n            box_mask[b_idx][pos_mask] = 1\n            box_targets[b_idx][pos_mask] = encode_boxes(\n                anchors[pos_mask].to(device),\n                gt_boxes[max_ids[pos_mask]]\n            )\n\n        valid_mask = cls_targets != -1\n        cls_inputs = cls_out[valid_mask]\n        cls_tg = cls_targets[valid_mask]\n\n        loss_cls = sigmoid_focal_loss(cls_inputs, cls_tg, alpha=0.25, gamma=2.0, reduction=\"sum\")\n        num_pos = box_mask.sum().clamp(min=1.0)\n        loss_cls = loss_cls / num_pos\n\n        pos_box = box_out[box_mask.bool()]\n        pos_tg = box_targets[box_mask.bool()]\n        loss_reg = smooth_l1_loss(pos_box, pos_tg, beta=1.0/9, reduction=\"sum\") / num_pos\n\n        return loss_cls, loss_reg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:03:37.334334Z","iopub.execute_input":"2025-11-26T13:03:37.334667Z","iopub.status.idle":"2025-11-26T13:03:37.411636Z","shell.execute_reply.started":"2025-11-26T13:03:37.334645Z","shell.execute_reply":"2025-11-26T13:03:37.410994Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import torchvision.transforms.functional as TF  # ðŸ‘ˆ NOTA: alias TF, non F\n\nclass ComposeTransforms:\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, image, target):\n        for t in self.transforms:\n            image, target = t(image, target)\n        return image, target\n\n\nclass ToTensor:\n    def __call__(self, image, target):\n        image = TF.to_tensor(image)  # ðŸ‘ˆ usiamo TF\n        return image, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T12:35:40.902949Z","iopub.execute_input":"2025-11-26T12:35:40.903741Z","iopub.status.idle":"2025-11-26T12:35:40.908634Z","shell.execute_reply.started":"2025-11-26T12:35:40.903711Z","shell.execute_reply":"2025-11-26T12:35:40.907797Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_sasi(num_epochs,global_step,model,train_loader,device,optimizer,lr_scheduler):\n        for epoch in range(num_epochs):\n            model.train()\n            running_loss = 0.0\n    \n            print(\"Inizio epoca\")\n            for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n                images = [img.to(device) for img in images]\n                for t in targets:\n                    t[\"boxes\"] = t[\"boxes\"].to(device)\n                    t[\"labels\"] = t[\"labels\"].to(device)\n    \n                losses = model(images, targets)\n                loss = losses[\"loss_cls\"] + losses[\"loss_reg\"]\n    \n                optimizer.zero_grad()\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n    \n                running_loss += loss.item()\n                global_step += 1\n    \n            lr_scheduler.step()\n            avg_loss = running_loss / len(train_loader)\n            print(f\"Epoch {epoch}: loss={avg_loss:.4f}\")\n    \n        # babysitting: salva checkpoint\n        #torch.save(model.state_dict(), f\"./retinanet_epoch_{epoch}.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:57:11.556628Z","iopub.execute_input":"2025-11-26T13:57:11.556938Z","iopub.status.idle":"2025-11-26T13:57:11.564433Z","shell.execute_reply.started":"2025-11-26T13:57:11.556913Z","shell.execute_reply":"2025-11-26T13:57:11.563655Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"\"\"\"RIDUZIONE DATASETS PER TEST\"\"\"\ndef daima(mini_size,dataset_train,dataset_val):\n    cartella = []\n    # 1. Definisci quanto grande vuoi che sia il tuo mini-set (es. 50 immagini)\n    mini_size = mini_size\n    \n    # 2. Crea una lista di indici (da 0 a 49)\n    # Puoi anche usare indici random se preferisci un campione casuale\n    indices = list(range(mini_size))\n\n    if dataset_train != None:\n        # 3. Crea il Subset\n        mini_dataset_train = Subset(dataset_train, indices)\n        \n        # 4. Crea il DataLoader specifico per il mini dataset\n        mini_loader_train = torch.utils.data.DataLoader(\n            mini_dataset_train, \n            batch_size=4,           # Stesso batch size o diverso, come preferisci\n            shuffle=True,           # Shuffle Ã¨ utile anche nel test per verificare che il modello non crashi\n            num_workers=2, \n            collate_fn=collate_fn   # Importante: mantieni la tua collate_fn\n        )\n        \n        print(f\"Dimensione dataset TRAIN originale: {len(dataset_train)}\")\n        print(f\"Dimensione mini TRAIN dataset: {len(mini_dataset_train)}\")\n\n        cartella.append(mini_loader_train)\n        \n\n    if dataset_val != None:\n        mini_dataset_val = Subset(dataset_val, indices)\n        # 4. Crea il DataLoader specifico per il mini dataset\n        mini_loader_val = torch.utils.data.DataLoader(\n            mini_dataset_val, \n            batch_size=4,           # Stesso batch size o diverso, come preferisci\n            shuffle=True,           # Shuffle Ã¨ utile anche nel test per verificare che il modello non crashi\n            num_workers=2, \n            collate_fn=collate_fn   # Importante: mantieni la tua collate_fn\n        )\n        \n        print(f\"Dimensione dataset VAL originale: {len(dataset_train)}\")\n        print(f\"Dimensione mini VAL dataset: {len(mini_dataset_train)}\")\n        cartella.append(mini_loader_val)\n    return cartella","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:26:42.684407Z","iopub.execute_input":"2025-11-26T13:26:42.685137Z","iopub.status.idle":"2025-11-26T13:26:42.690981Z","shell.execute_reply.started":"2025-11-26T13:26:42.685112Z","shell.execute_reply":"2025-11-26T13:26:42.690153Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# train.py\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import transforms\nfrom tqdm import tqdm\n\n\ndef collate_fn(batch):\n    \"\"\"\n    batch: lista di (image, target)\n    image: tensor [C,H,W] (giÃ  dopo ToTensor)\n    \"\"\"\n    images, targets = list(zip(*batch))\n\n    # trova altezza e larghezza massima nel batch\n    max_h = max(img.shape[1] for img in images)\n    max_w = max(img.shape[2] for img in images)\n\n    padded_images = []\n    for img in images:\n        c, h, w = img.shape\n        # crea immagine \"vuota\" (zero = nero) della size massima\n        pad = torch.zeros((c, max_h, max_w), dtype=img.dtype, device=img.device)\n        # copia l'immagine originale in alto a sinistra\n        pad[:, :h, :w] = img\n        padded_images.append(pad)\n\n    # targets li lasciamo cosÃ¬ come sono (i box non cambiano)\n    return padded_images, list(targets)\n\n\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    num_classes = 91  # COCO categories (incl. background handling via one-hot)\n    model = RetinaNet(num_classes=num_classes).to(device)\n\n    train_transforms = ComposeTransforms([\n        ToTensor(),\n        # puoi aggiungere qui random resize, flip, ecc.\n    ])\n\n    train_dataset = COCODetectionRetinaNet(\n        img_folder=\"/kaggle/input/cococustom/kaggle/working/train\",\n        ann_file=\"/kaggle/input/cococustom/kaggle/working/instances_train2017.json\",\n        transforms=train_transforms\n    )\n\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=2,\n        shuffle=True,\n        num_workers=0,      # tienilo 0 finchÃ© debuggiamo\n        collate_fn=collate_fn\n    )\n\n    train_loader = daima(50,train_dataset,None)[0]\n\n\n    optimizer = torch.optim.SGD(\n        model.parameters(),\n        lr=0.01,\n        momentum=0.9,\n        weight_decay=1e-4\n    )\n    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n        optimizer, milestones=[60, 80], gamma=0.1\n    )\n\n    num_epochs = 90\n    global_step = 0\n    train_sasi(num_epochs,global_step,model,train_loader,device,optimizer,lr_scheduler)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:57:20.694621Z","iopub.execute_input":"2025-11-26T13:57:20.694953Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=20.85s)\ncreating index...\nindex created!\nUsing 11829 valid images out of original 118287\nDimensione dataset TRAIN originale: 11829\nDimensione mini TRAIN dataset: 50\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: loss=1.6633\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: loss=1.6987\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: loss=1.6612\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: loss=1.6578\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: loss=1.6531\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: loss=1.6599\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: loss=1.6501\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: loss=1.6571\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: loss=1.6487\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: loss=1.6435\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: loss=1.6501\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: loss=1.6492\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: loss=1.6427\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: loss=1.6362\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: loss=1.6234\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: loss=1.6120\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: loss=1.6089\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: loss=1.5916\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: loss=1.5881\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: loss=1.5728\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: loss=1.5712\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: loss=1.5619\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: loss=1.5567\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: loss=1.5498\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: loss=1.5474\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: loss=1.5151\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: loss=1.5184\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: loss=1.5310\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: loss=1.5419\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: loss=1.5374\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30: loss=1.5500\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31: loss=1.5132\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32: loss=1.5113\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33: loss=1.5023\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34: loss=1.5005\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35: loss=1.5086\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36: loss=1.4857\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37: loss=1.4906\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38: loss=1.4850\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39: loss=1.4936\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40: loss=1.4791\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41: loss=1.4783\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42: loss=1.4934\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43: loss=1.4798\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44: loss=1.4605\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45: loss=1.4516\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46: loss=1.4736\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47: loss=1.4880\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48: loss=1.4598\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49: loss=1.4562\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50: loss=1.4445\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51: loss=1.4537\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52: loss=1.4735\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53: loss=1.4340\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54: loss=1.4382\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55: loss=1.4305\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56: loss=1.4485\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57: loss=1.4392\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58: loss=1.4712\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59: loss=1.4464\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 60: loss=1.4227\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61: loss=1.4078\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62: loss=1.3856\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63: loss=1.3996\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64: loss=1.3927\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65: loss=1.4066\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66: loss=1.4156\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67: loss=1.4010\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68: loss=1.3962\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69: loss=1.3817\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 70: loss=1.3971\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71: loss=1.3801\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72: loss=1.3681\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73: loss=1.3747\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74: loss=1.3702\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 75: loss=1.3720\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 76: loss=1.3709\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 77: loss=1.3903\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 78: loss=1.3621\nInizio epoca\n","output_type":"stream"},{"name":"stderr","text":"Epoch 79:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:03<00:01,  2.73it/s]","output_type":"stream"}],"execution_count":null}]}