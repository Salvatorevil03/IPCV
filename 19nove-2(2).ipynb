{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":13707763,"sourceType":"datasetVersion","datasetId":8720184}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.utils.data\nimport cv2\nimport os\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nimport torchvision.transforms.functional as F  \nimport torchvision\nfrom torchvision import datasets, models\nfrom torchvision.transforms import functional as FT\nfrom torchvision import transforms as T\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, sampler, random_split, Dataset\nfrom torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\nfrom tqdm import tqdm\nimport math\nimport copy\nimport numpy as np # linear algebra\nfrom torchvision.utils import draw_bounding_boxes\nimport albumentations as A  # our data augmentation library\nimport matplotlib.pyplot as plt\nimport warnings\nfrom collections import defaultdict, deque\nimport datetime\nimport time\nfrom tqdm import tqdm # progress bar\nfrom torchvision.utils import draw_bounding_boxes\nimport sys\nfrom torchmetrics.detection.mean_ap import MeanAveragePrecision\nfrom torch.utils.data import Subset\nimport pandas as pd\nfrom tqdm import tqdm\nimport random\nimport gc\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\nwarnings.filterwarnings(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-11-28T08:32:04.471741Z","iopub.execute_input":"2025-11-28T08:32:04.472018Z","iopub.status.idle":"2025-11-28T08:32:04.478316Z","shell.execute_reply.started":"2025-11-28T08:32:04.471998Z","shell.execute_reply":"2025-11-28T08:32:04.477433Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\"\"\"\nCLASSE DATASET\n\"\"\"\n\n\nclass MyReducedCocoDataset(torch.utils.data.Dataset):\n    def __init__(self, root, annotation_file, transforms=None):\n        self.root = root\n        self.transforms = transforms\n        self.coco = COCO(annotation_file) # Carica le annotazioni\n        all_ids = list(sorted(self.coco.imgs.keys())) ##mappo gli id in una lista ordinata\n        self.ids=[]\n\n        for img_id in tqdm(all_ids):\n            path = self.coco.loadImgs(img_id)[0]['file_name']\n            full_path = os.path.join(self.root, path)\n            \n            if os.path.exists(full_path):\n                self.ids.append(img_id)\n\n    def __getitem__(self, index):\n        # 1. Carica ID e path immagine\n        coco = self.coco\n        img_id = self.ids[index] #mi prendo id effettivo immagine\n        ann_ids = coco.getAnnIds(imgIds=img_id) #mi prendo le annotations\n        coco_annotation = coco.loadAnns(ann_ids)\n        \n        path = coco.loadImgs(img_id)[0]['file_name']\n        \n        img = Image.open(os.path.join(self.root, path)).convert(\"RGB\") ##pytorch vuole solo img in rgb\n\n        # 3. Estrai le Box e le Label\n        #nbisogna convertire i bounding box\n        num_objs = len(coco_annotation)\n        boxes = []\n        labels = []\n        areas = []\n        iscrowd = []\n\n        for i in range(num_objs):\n            xmin = coco_annotation[i]['bbox'][0]\n            ymin = coco_annotation[i]['bbox'][1]\n            xmax = xmin + coco_annotation[i]['bbox'][2] # COCO è x,y,w,h -> convertiamo in x,y,x,y\n            ymax = ymin + coco_annotation[i]['bbox'][3]\n            \n            boxes.append([xmin, ymin, xmax, ymax])\n            labels.append(coco_annotation[i]['category_id'])\n            areas.append(coco_annotation[i]['area'])\n            iscrowd.append(coco_annotation[i]['iscrowd'])\n\n        # Conversione in Tensori\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        image_id = torch.tensor([img_id])\n        area = torch.as_tensor(areas, dtype=torch.float32)\n        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n\n        # Gestione casi senza box (immagini vuote)\n        if num_objs == 0:\n            boxes = torch.zeros((0, 4), dtype=torch.float32)\n\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        target[\"iscrowd\"] = iscrowd\n\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n\n        if not isinstance(img, torch.Tensor):\n            img = F.to_tensor(img)\n    \n        return img, target\n\n    def __len__(self):\n        return len(self.ids)\n\ndef collate_fn(batch):\n    #((img1,target1),(img2,target2)) ---- ((img1,img2),(target1,target2))\n    return tuple(zip(*batch))","metadata":{"execution":{"iopub.status.busy":"2025-11-28T08:27:21.886415Z","iopub.execute_input":"2025-11-28T08:27:21.886894Z","iopub.status.idle":"2025-11-28T08:27:21.896912Z","shell.execute_reply.started":"2025-11-28T08:27:21.886871Z","shell.execute_reply":"2025-11-28T08:27:21.896223Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"IMG_DIR_TRAIN = '/kaggle/input/coco-reduced/kaggle/working/train'\nANN_FILE_TRAIN = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_train2017.json'\n\nIMG_DIR_VAL = '/kaggle/input/coco-reduced/kaggle/working/val'\nANN_FILE_VAL = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json'\n\ndataset_train = MyReducedCocoDataset(root=IMG_DIR_TRAIN, annotation_file=ANN_FILE_TRAIN)\ndata_loader_train = torch.utils.data.DataLoader(\n        dataset_train, \n        batch_size=8, \n        shuffle=True,\n        num_workers=2, \n        collate_fn=collate_fn\n)\n\ndataset_val = MyReducedCocoDataset(root=IMG_DIR_VAL, annotation_file=ANN_FILE_VAL)\ndata_loader_val = torch.utils.data.DataLoader(\n        dataset_val, \n        batch_size=8, \n        shuffle=True, \n        num_workers=2,\n        collate_fn=collate_fn\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T08:27:29.258164Z","iopub.execute_input":"2025-11-28T08:27:29.258461Z","iopub.status.idle":"2025-11-28T08:30:00.952480Z","shell.execute_reply.started":"2025-11-28T08:27:29.258440Z","shell.execute_reply":"2025-11-28T08:30:00.951829Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=18.97s)\ncreating index...\nindex created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118287/118287 [02:04<00:00, 949.17it/s] \n","output_type":"stream"},{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.72s)\ncreating index...\nindex created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5000/5000 [00:05<00:00, 955.16it/s] \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\"\"\"RIDUZIONE DATASETS PER TEST\"\"\"\n# 1. Definisci quanto grande vuoi che sia il tuo mini-set (es. 50 immagini)\nmini_size = 100\n\n# 2. Crea una lista di indici (da 0 a 49)\n# Puoi anche usare indici random se preferisci un campione casuale\nindices = list(range(mini_size))\n\n# 3. Crea il Subset\nmini_dataset_train = Subset(dataset_train, indices)\n\n# 4. Crea il DataLoader specifico per il mini dataset\nmini_loader_train = torch.utils.data.DataLoader(\n    mini_dataset_train, \n    batch_size=7,           # Stesso batch size o diverso, come preferisci\n    shuffle=True,           # Shuffle è utile anche nel test per verificare che il modello non crashi\n    num_workers=2, \n    collate_fn=collate_fn   # Importante: mantieni la tua collate_fn\n)\n\nprint(f\"Dimensione dataset TRAIN originale: {len(dataset_train)}\")\nprint(f\"Dimensione mini TRAIN dataset: {len(mini_dataset_train)}\")\n\nmini_dataset_val = Subset(dataset_val, indices)\n\n# 4. Crea il DataLoader specifico per il mini dataset\nmini_loader_val = torch.utils.data.DataLoader(\n    mini_dataset_val, \n    batch_size=7,           # Stesso batch size o diverso, come preferisci\n    shuffle=True,           # Shuffle è utile anche nel test per verificare che il modello non crashi\n    num_workers=2, \n    collate_fn=collate_fn   # Importante: mantieni la tua collate_fn\n)\n\nprint(f\"Dimensione dataset VAL originale: {len(dataset_train)}\")\nprint(f\"Dimensione mini VAL dataset: {len(mini_dataset_train)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T08:30:29.239302Z","iopub.execute_input":"2025-11-28T08:30:29.239602Z","iopub.status.idle":"2025-11-28T08:30:29.246006Z","shell.execute_reply.started":"2025-11-28T08:30:29.239579Z","shell.execute_reply":"2025-11-28T08:30:29.245215Z"}},"outputs":[{"name":"stdout","text":"Dimensione dataset TRAIN originale: 11829\nDimensione mini TRAIN dataset: 100\nDimensione dataset VAL originale: 11829\nDimensione mini VAL dataset: 100\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\"\"\"\nImportiamo il modello Faster RCNN ci torchvision\n\"\"\"\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='COCO_V1')\n\n\"\"\"\nAttivare la GPU\n\"\"\"\ndevice = torch.device(\"cuda\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2025-11-24T10:49:44.800610Z","iopub.execute_input":"2025-11-24T10:49:44.801468Z","iopub.status.idle":"2025-11-24T10:49:46.407671Z","shell.execute_reply.started":"2025-11-24T10:49:44.801440Z","shell.execute_reply":"2025-11-24T10:49:46.407076Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_smart(model, optimizer, train_loader, val_loader, device, num_epochs, save_path='.'):\n    \"\"\"\n    Funzione di training adattata per Object Detection con struttura avanzata:\n    - Training Loop\n    - Validation Loop\n    - Model Checkpointing (Best & Last)\n    - History return\n    \"\"\"\n    \n    # Setup history e variabili\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'train_sub_losses': [], # Per salvare classifier, box_reg, etc.\n        'val_sub_losses': []\n    }\n    \n    min_val_loss = np.inf\n    model.to(device)\n    \n    fit_time = time.time()\n    \n    print(f\"Inizio training su {device} per {num_epochs} epoche...\")\n\n    for epoch in range(num_epochs):\n        since = time.time()\n        \n        # --- TRAINING PHASE ---\n        model.train()\n        running_loss = 0.0\n        running_sub_losses = {} # Per accumulare le loss parziali (rpn, box, class, etc)\n        \n        # Nota: Se vuoi usare tqdm, avvolgi train_loader qui: tqdm(train_loader)\n        for i, (images, targets) in enumerate(train_loader):\n            \n            # Preparazione dati specifica per Object Detection\n            images = list(image.to(device) for image in images)\n            targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n\n            # Zero grad\n            optimizer.zero_grad()\n\n            # Forward pass (Il modello calcola la loss internamente se passiamo i targets)\n            loss_dict = model(images, targets)\n            \n            # Calcolo loss totale\n            losses = sum(loss for loss in loss_dict.values())\n            loss_value = losses.item()\n\n            # Controllo stabilità\n            if not math.isfinite(loss_value):\n                print(f\"\\nLoss is {loss_value}, stopping training\")\n                print(loss_dict)\n                sys.exit(1)\n\n            # Backward & Step\n            losses.backward()\n            optimizer.step()\n\n            # Accumulo metriche\n            running_loss += loss_value\n            \n            # Accumulo sotto-loss per statistiche (staccandole dal grafo)\n            for k, v in loss_dict.items():\n                if k not in running_sub_losses:\n                    running_sub_losses[k] = 0.0\n                running_sub_losses[k] += v.item()\n\n        # Media epocale train\n        epoch_train_loss = running_loss / len(train_loader)\n        epoch_train_sub = {k: v / len(train_loader) for k, v in running_sub_losses.items()}\n\n        # --- VALIDATION PHASE ---\n        # ATTENZIONE: Per i modelli di Detection Torchvision, se metti model.eval(),\n        # il modello restituisce predizioni (box), NON loss. \n        # Per monitorare la val_loss, rimaniamo in .train() ma con torch.no_grad().\n        running_val_loss = 0.0\n        running_val_sub_losses = {}\n        \n        with torch.no_grad():\n            # model.train() # Rimane tecnicamente in train mode per calcolare le loss\n            for images, targets in val_loader:\n                images = list(image.to(device) for image in images)\n                targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n\n                loss_dict = model(images, targets)\n                losses = sum(loss for loss in loss_dict.values())\n                \n                running_val_loss += losses.item()\n                \n                for k, v in loss_dict.items():\n                    if k not in running_val_sub_losses:\n                        running_val_sub_losses[k] = 0.0\n                    running_val_sub_losses[k] += v.item()\n\n        # Media epocale val\n        epoch_val_loss = running_val_loss / len(val_loader)\n        epoch_val_sub = {k: v / len(val_loader) for k, v in running_val_sub_losses.items()}\n\n        # --- SALVATAGGIO STORICO ---\n        history['train_loss'].append(epoch_train_loss)\n        history['val_loss'].append(epoch_val_loss)\n        history['train_sub_losses'].append(epoch_train_sub)\n        history['val_sub_losses'].append(epoch_val_sub)\n\n        # --- CHECKPOINTING (Best Model) ---\n        if epoch_val_loss < min_val_loss:\n            print('Loss Decreasing.. {:.4f} >> {:.4f} (Saving Model)'.format(min_val_loss, epoch_val_loss))\n            min_val_loss = epoch_val_loss\n            torch.save(model, f'{save_path}/model_best.pt')\n\n        # --- STAMPA STATISTICHE ---\n        time_elapsed = time.time() - since\n        print(\"Epoch:{}/{} | Time: {:.0f}m {:.0f}s\".format(epoch + 1, num_epochs, time_elapsed // 60, time_elapsed % 60))\n        print(f\"Train Loss: {epoch_train_loss:.5f} | Val Loss: {epoch_val_loss:.5f}\")\n        # Stampa opzionale di una componente specifica (es. classifier loss)\n        # print(f\"Train Class Loss: {epoch_train_sub.get('loss_classifier', 0):.5f}\") \n        print(\"-\" * 60)\n\n    # --- FINE TRAINING ---\n    total_time = time.time() - fit_time\n    print('Total training time: {:.0f}m {:.0f}s'.format(total_time // 60, total_time % 60))\n    print('Saving last model...')\n    torch.save(model, f'{save_path}/model_last.pt')\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2025-11-24T10:46:41.351460Z","iopub.execute_input":"2025-11-24T10:46:41.351848Z","iopub.status.idle":"2025-11-24T10:46:41.365085Z","shell.execute_reply.started":"2025-11-24T10:46:41.351816Z","shell.execute_reply":"2025-11-24T10:46:41.364221Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- ESEMPIO DI UTILIZZO ---\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T10:46:46.521422Z","iopub.execute_input":"2025-11-24T10:46:46.521757Z","iopub.status.idle":"2025-11-24T10:46:46.526658Z","shell.execute_reply.started":"2025-11-24T10:46:46.521732Z","shell.execute_reply":"2025-11-24T10:46:46.525834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assicurati di avere un data_loader_val definito\nhistory = train_smart(\n    model=model, \n    optimizer=optimizer, \n    train_loader=data_loader_train, \n    val_loader=data_loader_val,  # Serve un validation loader\n    device=device, \n    num_epochs=10\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Crea una nuova figura\nplt.figure(figsize=(10, 5)) # Opzionale: rende il grafico un po' più largo\n\n# Plot delle curve\nplt.plot(history['train_loss'], color='blue', label='Train Loss')\nplt.plot(history['val_loss'], color='red', label='Validation Loss')\n\n# Configurazioni\nplt.legend(loc='upper right')\nplt.xlabel('Epochs')\nplt.ylabel('Total Loss') # Corretto per Object Detection\nplt.title('Training vs Validation Loss')\nplt.grid(True, linestyle='--', alpha=0.6) # Opzionale: aggiunge una griglia per leggibilità\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_iou(box1, box2):\n    \"\"\"\n    Calcola l’IoU tra due bounding box.\n    box formato: [x_min, y_min, x_max, y_max]\n    \"\"\"\n    xA = max(box1[0], box2[0])\n    yA = max(box1[1], box2[1])\n    xB = min(box1[2], box2[2])\n    yB = min(box1[3], box2[3])\n\n    inter_w = max(0, xB - xA)\n    inter_h = max(0, yB - yA)\n    interArea = inter_w * inter_h\n\n    box1Area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    box2Area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n\n    iou = interArea / float(box1Area + box2Area - interArea + 1e-6)\n    return iou","metadata":{"execution":{"iopub.status.busy":"2025-11-24T10:46:51.847991Z","iopub.execute_input":"2025-11-24T10:46:51.848788Z","iopub.status.idle":"2025-11-24T10:46:51.853630Z","shell.execute_reply.started":"2025-11-24T10:46:51.848762Z","shell.execute_reply":"2025-11-24T10:46:51.853025Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sovrapposizione totale\nboxA = [10, 10, 50, 50]\nboxB = [10, 10, 50, 50]\nprint(\"IoU:\", compute_iou(boxA, boxB))\n\n# sovrapposizione parziale\nboxA = [10, 10, 50, 50]\nboxB = [30, 30, 70, 70]\nprint(\"IoU:\", compute_iou(boxA, boxB))\n\n# sovrapposizione assente\nboxA = [10, 10, 40, 40]\nboxB = [50, 50, 80, 80]\nprint(\"IoU:\", compute_iou(boxA, boxB))","metadata":{"execution":{"iopub.status.busy":"2025-11-24T10:46:54.119993Z","iopub.execute_input":"2025-11-24T10:46:54.120352Z","iopub.status.idle":"2025-11-24T10:46:54.125824Z","shell.execute_reply.started":"2025-11-24T10:46:54.120327Z","shell.execute_reply":"2025-11-24T10:46:54.124962Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nPrecision=TP/TP+FP\nRecall=TP/TP+FN\n\nCondizioni:\n1. Ha trovato l’oggetto nel punto giusto? Confronta ogni box predetto con quello reale usando la IoU\n2. Ha riconosciuto la classe giusta? Verifica che la label sia la stessa del Ground Truth\nSe entrambi sono veri: True Positive (TP)\nSe una delle due condizioni non è soddisfatta: False Positive (FP)\nSe un oggetto reale non viene mai trovato: False Negative (FN)\n\nNON è sufficiente per mAP\nper la quale serve fare Precision e Recall per ogni classe e per più soglie\n\"\"\"\ndef compute_precision_recall_fasterrcnn(predictions, targets, iou_threshold=0.5):\n    tp = 0\n    fp = 0\n    fn = 0\n\n    for pred, gt in zip(predictions, targets):\n\n        pred_boxes = pred[\"boxes\"].cpu().numpy()\n        pred_labels = pred[\"labels\"].cpu().numpy()\n        pred_scores = pred[\"scores\"].cpu().numpy()\n\n        gt_boxes = gt[\"boxes\"].cpu().numpy()\n        gt_labels = gt[\"labels\"].cpu().numpy()\n\n        matched_gt = set()\n\n        # Ordina predizioni per score decrescente\n        sorted_indices = np.argsort(-pred_scores)\n        pred_boxes = pred_boxes[sorted_indices]\n        pred_labels = pred_labels[sorted_indices]\n        pred_scores = pred_scores[sorted_indices]  # ⬅️ questa riga è fondamentale\n        \n        # Filtra predizioni con confidence troppo bassa\n        score_threshold = 0.05\n        valid = pred_scores >= score_threshold\n        pred_boxes = pred_boxes[valid]\n        pred_labels = pred_labels[valid]\n        pred_scores = pred_scores[valid]\n\n\n        for pb, pl in zip(pred_boxes, pred_labels):\n\n            best_iou = 0\n            best_gt = -1\n\n            for i, (gt_b, gt_l) in enumerate(zip(gt_boxes, gt_labels)):\n                \n                if i in matched_gt:\n                    continue  # già assegnato a un TP\n                \n                if pl != gt_l:\n                    continue  # classe sbagliata\n\n                iou = compute_iou(pb, gt_b)\n                if iou > best_iou:\n                    best_iou = iou\n                    best_gt = i\n\n            if best_iou >= iou_threshold and best_gt not in matched_gt:\n                tp += 1\n                matched_gt.add(best_gt)\n            else:\n                fp += 1\n        \n        fn += len(gt_boxes) - len(matched_gt)\n\n    precision = tp / (tp + fp + 1e-6)\n    recall = tp / (tp + fn + 1e-6)\n\n    return precision, recall","metadata":{"execution":{"iopub.status.busy":"2025-11-28T08:31:13.739565Z","iopub.execute_input":"2025-11-28T08:31:13.739862Z","iopub.status.idle":"2025-11-28T08:31:13.747563Z","shell.execute_reply.started":"2025-11-28T08:31:13.739842Z","shell.execute_reply":"2025-11-28T08:31:13.746911Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"predictions = [{\n    \"boxes\": torch.tensor([\n        [12, 12, 48, 48],   # match buono con la persona\n        [55, 55, 95, 95],   # box giusto sul cane, ma classe sbagliata\n        [0, 0, 20, 20],     # predizione su sfondo\n    ], dtype=torch.float32),\n    \"labels\": torch.tensor([\n        1,  # persona → CORRETTO\n        3,  # gatto → SBAGLIATO\n        1,  # persona → SBAGLIATO → FP\n    ]),\n    \"scores\": torch.tensor([\n        0.98, # molto alto\n        0.90,\n        0.30,\n    ])\n}]\n\ntargets = [{\n    \"boxes\": torch.tensor([\n        [10, 10, 50, 50],   # persona\n        [60, 60, 100, 100], # cane\n    ], dtype=torch.float32),\n    \"labels\": torch.tensor([\n        1,  # classe persona\n        2,  # classe cane\n    ])\n}]\n\nprecision, recall = compute_precision_recall_fasterrcnn(predictions, targets)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)","metadata":{"execution":{"iopub.status.busy":"2025-11-24T10:59:14.920136Z","iopub.execute_input":"2025-11-24T10:59:14.920620Z","iopub.status.idle":"2025-11-24T10:59:14.927636Z","shell.execute_reply.started":"2025-11-24T10:59:14.920595Z","shell.execute_reply":"2025-11-24T10:59:14.927030Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCosa misura la mAP?\nMisura quanto bene un modello:\n1. trova tutti gli oggetti corretti (completezza -> recall)\n2. evita falsi positivi (precisione -> precision)\nCome si ottiene la mAP?\n1. Per ogni classe si costruisce la Precision-Recall curve\n2. Si calcola l’Average Precision (AP) = area sotto quella curva\n3. Si calcola la media delle AP di tutte le classi -> Mean AP\n\nLa curva di colcola al variare della soglia\nChe cos’è la “soglia”?\nOgni predizione del detector ha un valore di confidence score\n(es: “sono 95% sicuro che questo è un cane”)\nSe scegli una soglia (es. 0.7) allora:\nSe lo score ≥ 0.7 -> accetto la predizione\nSe lo score < 0.7 -> la scarto\nVariando questa soglia ottieni situazioni diverse:\nSoglia\t    Predizioni\t            Precision\tRecall\nAlta (0.9)\tpoche ma sicure\t        ↑ alta\t    ↓ bassa\nBassa (0.3)\ttante, anche sbagliate\t↓ bassa\t    ↑ alta\nOgni soglia produce un punto diverso nella curva Precision–Recall\n\nNota: la mAP è in funzione anche della soglia della IoU\nfissata lei, si calcola il valore di mAP\n\"\"\"\ndef evaluate_map_from_data(predictions, targets, device=\"cuda\"):\n    metric = MeanAveragePrecision(box_format=\"xyxy\", class_metrics=True)\n\n    if device == \"cuda\" and not torch.cuda.is_available():\n        device = \"cpu\"\n\n    formatted_preds = []\n    formatted_targets = []\n\n    for pred in predictions:\n        formatted_preds.append({\n            \"boxes\": pred[\"boxes\"].to(device),\n            \"scores\": pred[\"scores\"].to(device),\n            \"labels\": pred[\"labels\"].to(device),\n        })\n\n    for tgt in targets:\n        formatted_targets.append({\n            \"boxes\": tgt[\"boxes\"].to(device),\n            \"labels\": tgt[\"labels\"].to(device),\n        })\n\n    metric.update(formatted_preds, formatted_targets)\n    results = metric.compute()\n\n    print(\"AP Per Classe:\")\n    for i, ap in enumerate(results[\"map_per_class\"]):\n        print(f\"  Classe {i}: {float(ap):.4f}\")\n\n    print(\"RISULTATI mAP\")\n    print(f\"mAP IoU=0.50:0.95: {results['map']:.4f}\")\n    print(f\"mAP IoU=0.50:      {results['map_50']:.4f}\")\n    print(f\"mAP IoU=0.75:      {results['map_75']:.4f}\")\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2025-11-28T08:31:27.090307Z","iopub.execute_input":"2025-11-28T08:31:27.091152Z","iopub.status.idle":"2025-11-28T08:31:27.097556Z","shell.execute_reply.started":"2025-11-28T08:31:27.091102Z","shell.execute_reply":"2025-11-28T08:31:27.096964Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"targets = [\n    {\"boxes\": torch.tensor([[10.,10.,60.,110.],[120.,40.,200.,160.]]), \"labels\": torch.tensor([0,1])},\n    {\"boxes\": torch.tensor([[15.,18.,65.,120.],[230.,60.,350.,200.]]), \"labels\": torch.tensor([0,2])},\n    {\"boxes\": torch.tensor([[50.,40.,120.,160.]]), \"labels\": torch.tensor([0])},\n    {\"boxes\": torch.tensor([[100.,30.,180.,140.],[20.,40.,80.,100.]]), \"labels\": torch.tensor([1,0])},\n    {\"boxes\": torch.tensor([[250.,80.,400.,250.]]), \"labels\": torch.tensor([2])}\n]\n\npredictions = [\n    {\"boxes\": torch.tensor([[12.,12.,58.,108.],[118.,42.,198.,158.],[200.,200.,260.,260.]]),\n     \"scores\": torch.tensor([0.97,0.88,0.12]), \"labels\": torch.tensor([0,1,1])},\n    {\"boxes\": torch.tensor([[16.,20.,60.,115.],[220.,55.,340.,205.],[250.,50.,300.,100.]]),\n     \"scores\": torch.tensor([0.91,0.86,0.40]), \"labels\": torch.tensor([0,2,1])},\n    {\"boxes\": torch.tensor([[45.,35.,118.,162.],[200.,200.,260.,260.]]),\n     \"scores\": torch.tensor([0.95,0.22]), \"labels\": torch.tensor([0,2])},\n    {\"boxes\": torch.tensor([[22.,38.,82.,102.],[90.,20.,175.,135.],[0.,0.,30.,30.]]),\n     \"scores\": torch.tensor([0.87,0.92,0.10]), \"labels\": torch.tensor([0,1,0])},\n    {\"boxes\": torch.tensor([[250.,82.,395.,248.],[90.,90.,150.,150.]]),\n     \"scores\": torch.tensor([0.90,0.20]), \"labels\": torch.tensor([2,0])}\n]\n\nresults = evaluate_map_from_data(predictions, targets, device=\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2025-11-24T10:47:04.280922Z","iopub.execute_input":"2025-11-24T10:47:04.281932Z","iopub.status.idle":"2025-11-24T10:47:04.348836Z","shell.execute_reply.started":"2025-11-24T10:47:04.281898Z","shell.execute_reply":"2025-11-24T10:47:04.348033Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBabysitting with randsearch DANILO\n\"\"\"\n# ==========================================\n# 1. FUNZIONE DI TRAINING (Invariata)\n# ==========================================\ndef train_one_epoch(model, optimizer, loader, device, epoch):\n    model.to(device)\n    model.train()\n    \n    all_losses = []\n    \n    # Barra di progresso per l'epoca\n    pbar = tqdm(loader, desc=f\"   Epoch {epoch}\", leave=False)\n    \n    for images, targets in pbar:\n        images = list(image.to(device) for image in images)\n        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n        \n        loss_dict = model(images, targets)\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n        \n        if not math.isfinite(loss_value):\n            return float('inf')\n        \n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        \n        all_losses.append(loss_value)\n        pbar.set_description(f\"   Loss: {loss_value:.4f}\")\n\n    return np.mean(all_losses)\n\n# ==========================================\n# 2. RANDOM SEARCH (LR + MOMENTUM)\n# ==========================================\ndef run_random_search_tuning(start_model, train_loader, device, num_trials=10, epochs_per_trial=10):\n    print(f\"--- Inizio Random Search (LR + Momentum) ---\")\n    print(f\"Trials: {num_trials} | Epochs per Trial: {epochs_per_trial}\")\n    \n    # Salviamo i pesi iniziali per il reset\n    initial_weights = copy.deepcopy(start_model.state_dict())\n    \n    best_config = None\n    best_loss = float('inf')\n    results = []\n\n    for trial in range(num_trials):\n        # --- A. Generazione Parametri Casuali ---\n        \n        # 1. Learning Rate (Scala Logaritmica tra 1e-5 e 1e-1)\n        lr_exponent = np.random.uniform(-5, -1) \n        current_lr = 10 ** lr_exponent\n        \n        # 2. Momentum (Scala Lineare tra 0.8 e 0.99)\n        # Il momentum è solitamente alto, valori sotto 0.8 sono rari per SGD in visione\n        current_momentum = np.random.uniform(0.9, 0.99)\n        \n        print(f\"\\n=== TRIAL {trial+1}/{num_trials} | LR: {current_lr:.6f} | Momentum: {current_momentum:.4f} ===\")\n        \n        # --- B. Reset Modello ---\n        model = copy.deepcopy(start_model)\n        model.load_state_dict(initial_weights)\n        model.to(device)\n        \n        # --- C. Optimizer con i parametri random ---\n        params = [p for p in model.parameters() if p.requires_grad]\n        optimizer = torch.optim.SGD(\n            params, \n            lr=current_lr, \n            momentum=current_momentum, # <-- Parametro dinamico\n            weight_decay=0.0005\n        )\n        \n        # --- D. Training Loop ---\n        final_loss = float('inf')\n        trial_failed = False\n        \n        for epoch in range(epochs_per_trial):\n            avg_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n            \n            if avg_loss == float('inf'):\n                print(f\"   -> Trial Fallito (Loss esplosa).\")\n                trial_failed = True\n                final_loss = float('inf')\n                break\n            \n            final_loss = avg_loss\n        \n        if not trial_failed:\n            print(f\"   -> Risultato: Loss Finale = {final_loss:.6f}\")\n        \n        # Salvataggio dati\n        results.append({\n            'lr': current_lr, \n            'momentum': current_momentum, \n            'loss': final_loss\n        })\n        \n        # Aggiornamento Best\n        if final_loss < best_loss:\n            best_loss = final_loss\n            best_config = {'lr': current_lr, 'momentum': current_momentum}\n            print(f\"   >>> NUOVO RECORD! (LR={current_lr:.6f}, Mom={current_momentum:.4f})\")\n\n    # --- FINE ---\n    print(\"\\n========================================\")\n    print(\"--- CLASSIFICA FINALE (Top 3) ---\")\n    \n    # Ordiniamo per loss (dal più basso al più alto)\n    results.sort(key=lambda x: x['loss'])\n    \n    for i, res in enumerate(results[:3]):\n        print(f\"{i+1}. Loss: {res['loss']:.6f} | LR: {res['lr']:.6f} | Mom: {res['momentum']:.4f}\")\n        \n    print(f\"\\nPARAMETRI VINCITORI DA USARE:\")\n    print(f\"Optimizer: SGD\")\n    print(f\"LR:       {best_config['lr']:.6f}\")\n    print(f\"Momentum: {best_config['momentum']:.4f}\")\n    \n    return best_config\n\n# ==========================================\n# 3. ESECUZIONE\n# ==========================================\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n#Pulizia CUDA\nif device.type == 'cuda':\n    print(\"Pulizia VRAM in corso per liberare memoria residua e frammentata...\")\n    gc.collect()\n    torch.cuda.empty_cache()\n\nstart_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None)\n\n# Assicurati di avere 'mini_loader_train'\nif 'mini_loader_train' in locals() or 'mini_loader_train' in globals():\n    best_params = run_random_search_tuning(\n        start_model, \n        mini_loader_train, \n        device, \n        num_trials=10,       # Numero di tentativi casuali\n        epochs_per_trial=10  # Epoche per ogni tentativo\n    )\nelse:\n    print(\"Devi definire 'mini_loader_train' prima di lanciare il codice.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nBabysitting PAOLO\n\"\"\"\n# ==========================================\n# 1. FUNZIONE DI TRAINING (Invariata)\n# ==========================================\ndef train_one_epoch(model, optimizer, loader, device, epoch):\n    model.to(device)\n    model.train()\n    \n    all_losses = []\n    \n    # tqdm con leave=False per non intasare la console durante i 100 step totali\n    pbar = tqdm(loader, desc=f\"    Epoch {epoch}\", leave=False)\n    \n    for images, targets in pbar:\n        # Gestione dei target come nel codice originale\n        images = list(image.to(device) for image in images)\n        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n        \n        loss_dict = model(images, targets)\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n        \n        if not math.isfinite(loss_value):\n            print(f\"Loss is {loss_value}, stopping training\")\n            # In caso di nan, ritorniamo infinito per scartare questo Trial\n            return float('inf')\n        \n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        \n        all_losses.append(loss_value)\n        pbar.set_description(f\"    Loss: {loss_value:.4f}\")\n\n    # Restituisce la MEDIA della loss di tutta l'epoca\n    return np.mean(all_losses)\n\n# ==========================================\n# 2. LOGICA RANDOM SEARCH (Modificata)\n# ==========================================\ndef run_random_search(start_model, train_loader, device, num_trials=10, epochs_per_trial=10):\n    print(f\"--- Inizio Random Search per (LR, Momentum) ---\")\n    print(f\"Trials: {num_trials} | Epochs per Trial: {epochs_per_trial}\")\n    \n    # PARAMETRI PER IL CAMPIONAMENTO\n    # LR: Distribuzione Gaussiana centrata su 0.01 (10^-2) con deviazione standard logaritmica\n    LR_MEAN_EXP = -(3.2013)  \n    LR_STD_EXP = -1.0    # Deviazione standard sull'esponente logaritmico (es. per esplorare da 10^-3 a 10^-1)\n    # Momentum: Distribuzione Uniforme nell'intervallo [0.8, 0.99]\n    MOMENTUM_LOW = 0.8\n    MOMENTUM_HIGH = 0.99\n    \n    # 1. Salviamo lo stato iniziale dei pesi per resettare ogni volta\n    initial_weights = copy.deepcopy(start_model.state_dict())\n    \n    best_lr = None\n    best_momentum = None\n    best_loss = float('inf')\n    results = []\n\n    for trial in range(num_trials):\n        # A. Generiamo gli iper-parametri casuali\n        \n        # 1. Campionamento LR (Gaussiano su scala logaritmica)\n        # Genera l'esponente logaritmico usando una gaussiana\n        lr_exponent = np.random.normal(loc=LR_MEAN_EXP, scale=LR_STD_EXP) \n        current_lr = 10 ** lr_exponent\n        \n        # Clampa LR nell'intervallo ragionevole [10^-5, 10^-1] per evitare overflow\n        if current_lr < 1e-5:\n            current_lr = 1e-5\n        elif current_lr > 1e-1:\n            current_lr = 1e-1\n            \n        # 2. Campionamento Momentum (Uniforme)\n        current_momentum = np.random.uniform(MOMENTUM_LOW, MOMENTUM_HIGH)\n        \n        print(f\"\\n=== TRIAL {trial+1}/{num_trials} | Testing LR: {current_lr:.6f} | Momentum: {current_momentum:.4f} ===\")\n        \n        # B. Resettiamo il modello allo stato iniziale\n        model = copy.deepcopy(start_model)\n        model.load_state_dict(initial_weights)\n        model.to(device)\n        \n        # C. Optimizer SGD (ora include il momentum campionato)\n        params = [p for p in model.parameters() if p.requires_grad]\n        optimizer = torch.optim.SGD(\n            params, \n            lr=current_lr, \n            momentum=current_momentum, # <--- Momentum campionato\n            weight_decay=0.0005\n        )\n        \n        # D. Training Loop per questo Trial\n        final_loss = float('inf')\n        for epoch in range(epochs_per_trial):\n            avg_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n            \n            if avg_loss == float('inf'):\n                print(\"    -> Loss esplosa (NaN/Inf). Trial fallito.\")\n                final_loss = float('inf')\n                break\n            \n            final_loss = avg_loss\n            \n        print(f\"    -> Risultato Trial {trial+1}: Loss Finale = {final_loss:.6f}\")\n        \n        # Salviamo i risultati\n        results.append({'lr': current_lr, 'momentum': current_momentum, 'loss': final_loss})\n        \n        # E. Aggiorniamo il best\n        if final_loss < best_loss:\n            best_loss = final_loss\n            best_lr = current_lr\n            best_momentum = current_momentum\n            print(f\"    >>> NUOVO RECORD! LR {best_lr:.6f}, Momentum {best_momentum:.4f} è il migliore finora.\")\n\n    print(\"\\n========================================\")\n    print(\"--- FINE RANDOM SEARCH ---\")\n    print(\"========================================\")\n    \n    # Ordiniamo i risultati per loss\n    results.sort(key=lambda x: x['loss'])\n    \n    print(\"\\nClassifica Top 3 coppie (LR, Momentum):\")\n    for i, res in enumerate(results[:3]):\n        print(f\"{i+1}. LR: {res['lr']:.6f}, Momentum: {res['momentum']:.4f} -> Loss: {res['loss']:.6f}\")\n        \n    print(f\"\\nIL VINCITORE È: LR = {best_lr:.6f}, Momentum = {best_momentum:.4f}\")\n    return best_lr, best_momentum\n\n# ==========================================\n# 3. ESECUZIONE (Modificata per restituire due valori)\n# ==========================================\n\n# Configurazione Device\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(f\"Usando device: {device}\")\n\n#Pulizia CUDA\nif device.type == 'cuda':\n    print(\"Pulizia VRAM in corso per liberare memoria residua e frammentata...\")\n    gc.collect()\n    torch.cuda.empty_cache()\n\n# Prepara il modello (solo architettura)\n# Abbiamo bisogno di più classi se usiamo il dataset COCO ridotto (che ha 80 classi + 1 background)\nNUM_CLASSES = 91 # Se stai usando il COCO completo (80 + 1 background) o il COCO ridotto standard. Adatta questo se il tuo dataset ridotto ha un numero di classi diverso.\nstart_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n    weights=None, \n    num_classes=NUM_CLASSES # Aggiungo num_classes per chiarezza, anche se weights=None lo farebbe automaticamente.\n)\n\n# Assicurati che mini_loader_train sia definito\nif 'mini_loader_train' in locals() or 'mini_loader_train' in globals():\n    # La funzione ora ritorna la coppia (LR, Momentum)\n    best_lr, best_momentum = run_random_search(\n        start_model, \n        mini_loader_train, \n        device, \n        num_trials=10,     # Provo 10 coppie diverse\n        epochs_per_trial=10 # Addestro per 10 epoche ciascuno\n    )\nelse:\n    print(\"ERRORE: Definisci 'mini_loader_train' prima di eseguire.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nStessa di sopra ma plotta per ogni batch\n\"\"\"\ndef train_smart_realtime(model, optimizer, train_loader, val_loader, device, num_epochs, save_path='.'):\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'train_sub_losses': [],\n        'val_sub_losses': []\n    }\n    \n    min_val_loss = np.inf\n    model.to(device)\n    \n    fit_time = time.time()\n    print(f\"Inizio training su {device} per {num_epochs} epoche...\")\n\n    for epoch in range(num_epochs):\n        since = time.time()\n        \n        # --- TRAINING PHASE ---\n        model.train()\n        running_loss = 0.0\n        running_sub_losses = {}\n        \n        # 1. Creiamo la barra di progresso (tqdm) sul train_loader\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [TRAIN]\", leave=False)\n        \n        # Usiamo pbar invece di train_loader nel ciclo\n        for images, targets in pbar:\n            \n            images = list(image.to(device) for image in images)\n            targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n\n            optimizer.zero_grad()\n\n            loss_dict = model(images, targets)\n            losses = sum(loss for loss in loss_dict.values())\n            loss_value = losses.item()\n\n            if not math.isfinite(loss_value):\n                print(f\"\\nLoss is {loss_value}, stopping training\")\n                sys.exit(1)\n\n            losses.backward()\n            optimizer.step()\n\n            # Accumulo metriche\n            running_loss += loss_value\n            for k, v in loss_dict.items():\n                if k not in running_sub_losses:\n                    running_sub_losses[k] = 0.0\n                running_sub_losses[k] += v.item()\n            \n            # 2. AGGIORNAMENTO ON-TIME: Mostriamo la loss corrente nella barra\n            # 'loss': mostra la loss dell'ultimo batch (istantanea)\n            # 'avg': mostra la media accumulata fino ad ora\n            current_avg = running_loss / (pbar.n + 1)\n            pbar.set_postfix({'batch_loss': loss_value, 'running_avg': current_avg})\n\n        # Media epocale train (calcolata alla fine della barra)\n        epoch_train_loss = running_loss / len(train_loader)\n        epoch_train_sub = {k: v / len(train_loader) for k, v in running_sub_losses.items()}\n\n        # --- VALIDATION PHASE ---\n        running_val_loss = 0.0\n        running_val_sub_losses = {}\n        \n        # 3. Barra di progresso anche per la validazione\n        pbar_val = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [VAL]\", leave=False)\n        \n        with torch.no_grad():\n            for images, targets in pbar_val:\n                images = list(image.to(device) for image in images)\n                targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n\n                loss_dict = model(images, targets)\n                losses = sum(loss for loss in loss_dict.values())\n                \n                loss_val_value = losses.item()\n                running_val_loss += loss_val_value\n                \n                for k, v in loss_dict.items():\n                    if k not in running_val_sub_losses:\n                        running_val_sub_losses[k] = 0.0\n                    running_val_sub_losses[k] += v.item()\n                \n                # Aggiornamento barra validazione\n                pbar_val.set_postfix({'val_loss': loss_val_value})\n\n        epoch_val_loss = running_val_loss / len(val_loader)\n        epoch_val_sub = {k: v / len(val_loader) for k, v in running_val_sub_losses.items()}\n\n        # --- SALVATAGGIO STORICO ---\n        history['train_loss'].append(epoch_train_loss)\n        history['val_loss'].append(epoch_val_loss)\n        history['train_sub_losses'].append(epoch_train_sub)\n        history['val_sub_losses'].append(epoch_val_sub)\n\n        # --- CHECKPOINTING ---\n        if epoch_val_loss < min_val_loss:\n            # Opzionale: stampa un messaggio quando trovi un nuovo best\n            # print(f\"  --> New Best found! ({min_val_loss:.4f} -> {epoch_val_loss:.4f})\")\n            min_val_loss = epoch_val_loss\n            torch.save(model, f'{save_path}/model_best.pt')\n\n        # --- STAMPA FINALE EPOCA (Riepilogo pulito) ---\n        time_elapsed = time.time() - since\n        \n        # Stampa pulita che non viene sovrascritta dalla barra\n        print(f\"Epoch {epoch + 1}/{num_epochs} | Time: {time_elapsed:.0f}s | \"\n              f\"Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f} \"\n              f\"{'(*BEST*)' if epoch_val_loss == min_val_loss else ''}\")\n\n    total_time = time.time() - fit_time\n    print('Total training time: {:.0f}m {:.0f}s'.format(total_time // 60, total_time % 60))\n    torch.save(model, f'{save_path}/model_last.pt')\n    \n    return history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T08:32:17.922361Z","iopub.execute_input":"2025-11-28T08:32:17.922765Z","iopub.status.idle":"2025-11-28T08:32:17.935003Z","shell.execute_reply.started":"2025-11-28T08:32:17.922743Z","shell.execute_reply":"2025-11-28T08:32:17.934369Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\"\"\"\nInizio Train\n\"\"\"\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\n#Pulizia CUDA\nif device.type == 'cuda':\n    print(\"Pulizia VRAM in corso per liberare memoria residua e frammentata...\")\n    gc.collect()\n    torch.cuda.empty_cache()\n\n\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None)\nmodel.train()\n\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.004862, momentum= 0.9497,weight_decay=0.0005)\n        \nNUM_EPOCHS=5\nSAVE_DIR=\"/kaggle/working/\"\n# Usa i loader che hai già\nloader_t = mini_loader_train\n# Se non hai un val loader, usa il train loader anche per validation per ora\nloader_v = mini_loader_val\n    \n\n# Avvio\nhistory = train_smart_realtime(\n        model=model,\n        optimizer=optimizer,\n        train_loader=loader_t,\n        val_loader=loader_v,\n        device=device,\n        num_epochs=NUM_EPOCHS,\n        save_path=SAVE_DIR\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T08:32:23.941765Z","iopub.execute_input":"2025-11-28T08:32:23.942036Z","execution_failed":"2025-11-28T08:32:57.605Z"}},"outputs":[{"name":"stdout","text":"Pulizia VRAM in corso per liberare memoria residua e frammentata...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 212MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Inizio training su cuda per 5 epoche...\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 | Time: 29s | Train Loss: 2.5038 | Val Loss: 1.8947 (*BEST*)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5 [TRAIN]:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def plot_losses(history):\n    \"\"\"\n    Plotta le curve di loss per Train e Validation.\n    Gestisce sia la loss totale che le sotto-loss (se presenti).\n    \"\"\"\n    \n    # 1. Recupero Dati Principali\n    train_loss = history.get('train_loss', [])\n    val_loss = history.get('val_loss', [])\n    epochs = range(1, len(train_loss) + 1)\n    \n    # --- GRAFICO 1: LOSS TOTALE ---\n    plt.figure(figsize=(10, 6))\n    plt.plot(epochs, train_loss, 'b-', label='Training Loss', linewidth=2)\n    \n    if val_loss:\n        plt.plot(epochs, val_loss, 'r--', label='Validation Loss', linewidth=2)\n        \n        # Evidenzia il punto minimo della validation loss\n        min_val = min(val_loss)\n        min_epoch = val_loss.index(min_val) + 1\n        plt.scatter(min_epoch, min_val, s=100, c='green', marker='o', label=f'Best Model (Ep {min_epoch})')\n        plt.annotate(f'{min_val:.4f}', (min_epoch, min_val), textcoords=\"offset points\", xytext=(0,10), ha='center', color='green')\n\n    plt.title('Andamento Loss Totale (Faster R-CNN)', fontsize=16)\n    plt.xlabel('Epoche', fontsize=12)\n    plt.ylabel('Loss', fontsize=12)\n    plt.legend()\n    plt.grid(True, linestyle='--', alpha=0.7)\n    plt.show()\n\n    # --- GRAFICO 2: SOTTO-LOSS (CLASSIFIER, BOX, RPN...) ---\n    # Questo parte solo se la history ha salvato i dettagli (train_sub_losses)\n    if 'train_sub_losses' in history and len(history['train_sub_losses']) > 0:\n        \n        # Recuperiamo le chiavi delle sotto-loss dal primo elemento\n        keys = history['train_sub_losses'][0].keys()\n        num_plots = len(keys)\n        \n        # Creiamo una griglia di grafici\n        rows = math.ceil(num_plots / 2)\n        fig, axes = plt.subplots(rows, 2, figsize=(15, 5 * rows))\n        fig.suptitle('Dettaglio Componenti della Loss', fontsize=16)\n        axes = axes.flatten()\n        \n        for i, key in enumerate(keys):\n            ax = axes[i]\n            \n            # Estrai i dati per questa specifica loss (es. loss_classifier)\n            sub_train = [h[key] for h in history['train_sub_losses']]\n            \n            ax.plot(epochs, sub_train, label=f'Train {key}', color='tab:blue')\n            \n            # Se abbiamo anche i dettagli della validation\n            if 'val_sub_losses' in history and len(history['val_sub_losses']) > 0:\n                sub_val = [h[key] for h in history['val_sub_losses']]\n                ax.plot(epochs, sub_val, label=f'Val {key}', color='tab:orange', linestyle='--')\n            \n            ax.set_title(key)\n            ax.set_xlabel('Epoche')\n            ax.set_ylabel('Loss')\n            ax.legend()\n            ax.grid(True, alpha=0.5)\n            \n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n        plt.show()\n\n# --- ESEMPIO DI UTILIZZO ---\n# Assicurati di aver eseguito il training prima di lanciare questa riga\nif 'history' in locals():\n    plot_losses(history)\nelse:\n    print(\"Variabile 'history' non trovata. Esegui prima il training!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef evaluate_detector(model, dataloader, device=\"cuda\", iou_threshold=0.5, visualize=True, vis_score_threshold=0.5):\n    model.to(device)\n    model.eval()\n\n    all_predictions = []\n    all_targets = []\n\n    # variabili per memorizzare l’ultimo batch per la visualizzazione\n    last_images = None\n    last_predictions = None\n    last_targets = None\n\n    with torch.no_grad():\n        for images, targets in dataloader:\n            images = [img.to(device) for img in images]\n            targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n\n            predictions = model(images)\n\n            # accumulo predizioni e target per le metriche\n            all_predictions.extend(predictions)\n            all_targets.extend(targets)\n\n            # salvo l’ultimo batch per il plot\n            last_images = images\n            last_predictions = predictions\n            last_targets = targets\n\n    # CALCOLO METRICHE\n    precision, recall = compute_precision_recall_fasterrcnn(all_predictions, all_targets, iou_threshold=iou_threshold)\n    map_results = evaluate_map_from_data(all_predictions, all_targets, device=device)\n\n    # OUTPUT METRICHE\n    print(\"\\n📌 RISULTATI VALIDAZIONE\")\n    print(f\"Precision (IoU ≥ {iou_threshold}): {precision:.4f}\")\n    print(f\"Recall    (IoU ≥ {iou_threshold}): {recall:.4f}\")\n    print(\"\\n--- mAP ---\")\n    print(f\"mAP@0.50:0.95 = {map_results['map']:.4f}\")\n    print(f\"mAP@0.50      = {map_results['map_50']:.4f}\")\n    print(f\"mAP@0.75      = {map_results['map_75']:.4f}\")\n\n    # VISUALIZZAZIONE\n    if visualize and last_images is not None:\n        idx = 0  # prima immagine del batch\n        img = last_images[idx].permute(1,2,0).cpu().numpy()\n\n        plt.figure(figsize=(8,8))\n        plt.imshow(img)\n        plt.title(\"Bounding Box Detection (Green = GT, Red = Pred)\")\n        plt.axis(\"off\")\n\n        # BOX GROUND TRUTH\n        for box in last_targets[idx][\"boxes\"].cpu().numpy():\n            x1, y1, x2, y2 = box\n            plt.gca().add_patch(\n                plt.Rectangle((x1,y1), x2-x1, y2-y1,\n                              fill=False, linewidth=2, edgecolor=\"lime\")\n            )\n\n        # BOX PREDETTE - SOLO SCORE ALTO\n        pred_boxes = last_predictions[idx][\"boxes\"].cpu().numpy()\n        pred_scores = last_predictions[idx][\"scores\"].cpu().numpy()\n\n        valid = pred_scores >= vis_score_threshold\n        pred_boxes = pred_boxes[valid]\n        pred_scores = pred_scores[valid]\n\n        for box, score in zip(pred_boxes, pred_scores):\n            x1, y1, x2, y2 = box\n            plt.gca().add_patch(\n                plt.Rectangle((x1,y1), x2-x1, y2-y1,\n                              fill=False, linewidth=2, edgecolor=\"red\")\n            )\n            plt.text(x1, y1-5, f\"{score:.2f}\", color=\"yellow\", fontsize=8)\n\n        plt.show()\n\n    return precision, recall, map_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T11:13:19.608926Z","iopub.execute_input":"2025-11-24T11:13:19.609723Z","iopub.status.idle":"2025-11-24T11:13:19.620442Z","shell.execute_reply.started":"2025-11-24T11:13:19.609670Z","shell.execute_reply":"2025-11-24T11:13:19.619745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\niou_threshold è della precision singola calcolata\n\"\"\"\nprecision, recall, map_results = evaluate_detector(model, data_loader_val, device=\"cuda\", iou_threshold=0.5)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T11:14:29.720786Z","iopub.execute_input":"2025-11-24T11:14:29.721605Z","iopub.status.idle":"2025-11-24T11:15:17.569768Z","shell.execute_reply.started":"2025-11-24T11:14:29.721573Z","shell.execute_reply":"2025-11-24T11:15:17.569057Z"}},"outputs":[],"execution_count":null}]}