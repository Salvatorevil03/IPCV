{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":13707763,"sourceType":"datasetVersion","datasetId":8720184}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport os\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nfrom tqdm.notebook import tqdm  # Per vedere la barra di progresso del filtro\n\nclass CocoFasterRCNNDataset(Dataset):\n    def __init__(self, root, annotation, transforms=None):\n        self.root = root\n        self.transforms = transforms\n        self.coco = COCO(annotation)\n        \n        # --- MODIFICA FONDAMENTALE QUI ---\n        # Invece di prendere tutti gli ID dal JSON alla cieca:\n        # self.ids = list(sorted(self.coco.imgs.keys()))\n        \n        # Facciamo un controllo preventivo:\n        all_ids = list(sorted(self.coco.imgs.keys()))\n        self.ids = []\n        \n        print(\"Verifica delle immagini presenti su disco in corso...\")\n        # Scansioniamo gli ID e teniamo solo quelli che hanno un file corrispondente\n        for img_id in tqdm(all_ids):\n            path = self.coco.loadImgs(img_id)[0]['file_name']\n            full_path = os.path.join(self.root, path)\n            \n            if os.path.exists(full_path):\n                self.ids.append(img_id)\n        \n        print(f\"Fatto! Trovate {len(self.ids)} immagini su disco (rispetto alle {len(all_ids)} nel JSON).\")\n        # ----------------------------------\n\n    def __getitem__(self, index):\n        coco = self.coco\n        img_id = self.ids[index]\n        ann_ids = coco.getAnnIds(imgIds=img_id)\n        coco_annotation = coco.loadAnns(ann_ids)\n        \n        path = coco.loadImgs(img_id)[0]['file_name']\n        # Qui ora siamo sicuri che il file esiste!\n        img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n\n        num_objs = len(coco_annotation)\n        boxes = []\n        labels = []\n        areas = []\n        iscrowd = []\n\n        for i in range(num_objs):\n            xmin = coco_annotation[i]['bbox'][0]\n            ymin = coco_annotation[i]['bbox'][1]\n            w = coco_annotation[i]['bbox'][2]\n            h = coco_annotation[i]['bbox'][3]\n            \n            xmax = xmin + w\n            ymax = ymin + h\n            \n            boxes.append([xmin, ymin, xmax, ymax])\n            labels.append(coco_annotation[i]['category_id'])\n            areas.append(coco_annotation[i]['area'])\n            iscrowd.append(coco_annotation[i]['iscrowd'])\n\n        # Gestione immagini senza box (background only)\n        if num_objs > 0:\n            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n            labels = torch.as_tensor(labels, dtype=torch.int64)\n            areas = torch.as_tensor(areas, dtype=torch.float32)\n            iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n        else:\n            boxes = torch.zeros((0, 4), dtype=torch.float32)\n            labels = torch.zeros((0,), dtype=torch.int64)\n            areas = torch.zeros((0,), dtype=torch.float32)\n            iscrowd = torch.zeros((0,), dtype=torch.int64)\n\n        image_id = torch.tensor([img_id])\n\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"image_id\"] = image_id\n        target[\"area\"] = areas\n        target[\"iscrowd\"] = iscrowd\n\n        if self.transforms is not None:\n            img = self.transforms(img)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.ids)\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T14:31:12.542270Z","iopub.execute_input":"2025-11-18T14:31:12.542745Z","iopub.status.idle":"2025-11-18T14:31:12.675650Z","shell.execute_reply.started":"2025-11-18T14:31:12.542720Z","shell.execute_reply":"2025-11-18T14:31:12.675111Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Percorsi (aggiornali se necessario)\nIMG_DIR = '/kaggle/input/coco-reduced/kaggle/working/train'\nANN_FILE = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_train2017.json'\n\n# Trasformazione base\ndef get_transform():\n    return T.Compose([T.ToTensor()])\n\n# Istanziamo il Dataset\ndataset = CocoFasterRCNNDataset(\n    root=IMG_DIR,\n    annotation=ANN_FILE,\n    transforms=get_transform()\n)\n\n# Creiamo il DataLoader\ndata_loader = DataLoader(\n    dataset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=2,\n    collate_fn=collate_fn\n)\n\nprint(\"✅ Dataset e DataLoader creati con successo (Custom Class).\")\n\n# --- VERIFICA FUNZIONAMENTO ---\n# Estraiamo un batch per essere sicuri al 100%\ntry:\n    images, targets = next(iter(data_loader))\n    print(f\"\\nBatch caricato!\")\n    print(f\"Numero immagini: {len(images)}\")\n    print(f\"Shape prima immagine: {images[0].shape}\")\n    print(f\"Target keys: {targets[0].keys()}\")\n    print(f\"Box format (primo box): {targets[0]['boxes'][0] if len(targets[0]['boxes']) > 0 else 'Nessun box'}\")\nexcept Exception as e:\n    print(f\"❌ Errore: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T14:31:12.676778Z","iopub.execute_input":"2025-11-18T14:31:12.677065Z","iopub.status.idle":"2025-11-18T14:33:27.697434Z","shell.execute_reply.started":"2025-11-18T14:31:12.677038Z","shell.execute_reply":"2025-11-18T14:33:27.696664Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=20.65s)\ncreating index...\nindex created!\nVerifica delle immagini presenti su disco in corso...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118287 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c83b7d3a7584d36a3d25ff22e37cc93"}},"metadata":{}},{"name":"stdout","text":"Fatto! Trovate 11829 immagini su disco (rispetto alle 118287 nel JSON).\n✅ Dataset e DataLoader creati con successo (Custom Class).\n\nBatch caricato!\nNumero immagini: 4\nShape prima immagine: torch.Size([3, 427, 640])\nTarget keys: dict_keys(['boxes', 'labels', 'image_id', 'area', 'iscrowd'])\nBox format (primo box): tensor([145.2300,  36.9700, 232.3900,  73.5400])\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\"\"\"Esempio minimale di Train per asserire la correttezza e usabilità del dataloader.\"\"\"\nimport torch\nimport torchvision\nfrom torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n\n# --- 1. Definiamo il Modello ---\n# Carichiamo il modello pre-addestrato su COCO.\n# Questo modello ha 91 classi (90 oggetti + 1 background), che combaciano con gli ID del tuo JSON.\nprint(\"Caricamento modello...\")\nweights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=weights)\n\n# --- 2. Setup del Device ---\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f\"Using device: {device}\")\n\n# Spostiamo il modello sulla GPU\nmodel.to(device)\n\n# --- 3. Training Loop Minimale ---\n# Mettiamo il modello in modalità train (restituisce le loss)\nmodel.train()\n\n# Definiamo l'optimizer\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n\nprint(\"Inizio test training (solo 10 batch)...\")\n\nfor i, (images, targets) in enumerate(data_loader):\n    \n    # Spostiamo le immagini e i target su GPU\n    images = list(image.to(device) for image in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n    # Forward Pass (Calcolo Loss)\n    loss_dict = model(images, targets)\n    losses = sum(loss for loss in loss_dict.values())\n\n    # Backward Pass (Aggiornamento Pesi)\n    optimizer.zero_grad()\n    losses.backward()\n    optimizer.step()\n\n    # Log\n    print(f\"Batch {i+1} | Total Loss: {losses.item():.4f}\")\n    \n    if i == 0:\n        print(\"\\n   Dettaglio Loss (Batch 1):\")\n        for k, v in loss_dict.items():\n            print(f\"   - {k}: {v.item():.4f}\")\n        print(\"-\" * 30)\n\n    # Stop dopo 10 batch\n    if i >= 9:\n        print(\"\\n✅ Test completato! Tutto funzionante.\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T14:33:27.698391Z","iopub.execute_input":"2025-11-18T14:33:27.698605Z","iopub.status.idle":"2025-11-18T14:33:37.685068Z","shell.execute_reply.started":"2025-11-18T14:33:27.698583Z","shell.execute_reply":"2025-11-18T14:33:37.684048Z"}},"outputs":[{"name":"stdout","text":"Caricamento modello...\nUsing device: cuda\nInizio test training (solo 10 batch)...\nBatch 1 | Total Loss: 0.8919\n\n   Dettaglio Loss (Batch 1):\n   - loss_classifier: 0.3101\n   - loss_box_reg: 0.3642\n   - loss_objectness: 0.1268\n   - loss_rpn_box_reg: 0.0908\n------------------------------\nBatch 2 | Total Loss: 0.4024\nBatch 3 | Total Loss: 0.6977\nBatch 4 | Total Loss: 0.6152\nBatch 5 | Total Loss: 0.3278\nBatch 6 | Total Loss: 0.3012\nBatch 7 | Total Loss: 0.5618\nBatch 8 | Total Loss: 0.4676\nBatch 9 | Total Loss: 0.6221\nBatch 10 | Total Loss: 0.2586\n\n✅ Test completato! Tutto funzionante.\n","output_type":"stream"}],"execution_count":5}]}